<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="机器学习之概率论" />
<meta property="og:description" content="本篇介绍概率统计相关知识，后续机器学习中朴素贝叶斯算法用到了其中贝叶斯的原理，在文本处理方便也有着广泛的应用。
" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://maodanp.github.io/2017/04/10/probability/" />



<meta property="article:published_time" content="2017-04-10T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2017-04-10T00:00:00&#43;00:00"/>











<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="机器学习之概率论"/>
<meta name="twitter:description" content="本篇介绍概率统计相关知识，后续机器学习中朴素贝叶斯算法用到了其中贝叶斯的原理，在文本处理方便也有着广泛的应用。
"/>


    <link rel="canonical" href="http://maodanp.github.io/2017/04/10/probability/">

    <title>
      
        机器学习之概率论 | Danping&#39;s Blog
      
    </title>

    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <link href="http://maodanp.github.io/css/style.css" rel="stylesheet">

    

    

    
  </head>
  <body>
    
      <header class="blog-header">
    <nav class="navbar navbar-expand-md navbar-light bg-light">
        <a class="navbar-brand" href="/">
            Danping&#39;s Blog
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false"
            aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse justify-content-between" id="navbarNav">
            <ul class="navbar-nav">
                
                
                <li class="nav-item ">
                    <a class="nav-link" href="/">主页</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="/categories/%e6%8a%80%e6%9c%af%e5%bf%97/">技术志</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="/categories/%E5%B7%A5%E5%85%B7%E7%AE%B1/">工具箱</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="/categories/%e6%9d%82%e8%b0%88%e9%9b%86/">杂谈集</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="/about/">关于</a>
                </li>
                
            </ul>
            
        </div>
	<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>
    </nav>
</header>

    

    
    <div class="container">
      <div class="row">
        <div class="col-12 col-lg-8 blog-main">

          

<article class="blog-post">
    <header>
        <h2 class="blog-post-title">
            <a class="text-dark" href="/2017/04/10/probability/">机器学习之概率论</a>
        </h2>
        


<div class="blog-post-date text-secondary">
    
        Apr 10, 2017
    
    
        by Danping Mao
    
</div>
        
<div class="blog-post-tags text-secondary">
    <strong>Tags:</strong>
    
        <a class="badge badge-primary" href="/tags/machine-learning">machine learning</a>
    
</div>

        
<div class="blog-post-categories text-secondary">
    <strong>Categories:</strong>
    
        <a class="badge badge-primary" href="/categories/%E6%8A%80%E6%9C%AF%E5%BF%97">技术志</a>
    
</div>

    </header>
    <hr>
    <p>本篇介绍概率统计相关知识，后续机器学习中朴素贝叶斯算法用到了其中贝叶斯的原理，在文本处理方便也有着广泛的应用。
</p>

<h2 id="概率论基础">概率论基础</h2>

<h3 id="概率与直观">概率与直观</h3>

<p>给定某正整数N，从1到N的所有数所对应的阶乘中，首位数字出现1的概率？</p>

<ul>
<li>本福特定律/第一数字定律</li>
</ul>

<p>实际生活中得出的一组数据中，以1位首位数字出现的概率<strong>约为总数的三成</strong>。</p>

<table>
<thead>
<tr>
<th>数字</th>
<th>出现概率</th>
</tr>
</thead>

<tbody>
<tr>
<td>1</td>
<td>30.1%</td>
</tr>

<tr>
<td>2</td>
<td>17.6%</td>
</tr>

<tr>
<td>3</td>
<td>12.5%</td>
</tr>

<tr>
<td>4</td>
<td>9.7%</td>
</tr>

<tr>
<td>5</td>
<td>7.9%</td>
</tr>
</tbody>
</table>

<p>包括：</p>

<ul>
<li>阶乘/素数数列/斐波那契数列首位</li>
<li>住在地址号码</li>
<li>经济数据反欺诈</li>
<li>选举投票反欺诈</li>
</ul>

<h3 id="贝叶斯公式">贝叶斯公式</h3>

<p><code>$$
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
$$</code></p>

<ul>
<li>$P(A)$: 没有数据支持下，A发生的概率；先验概率（在B事件发生之前，我们对A事件的一个判断）</li>
<li>$P(A|B)$: 在数据B的支持下，A发生的概率；后验概率（在B事件发生之后，我们对A事件的一个评估）</li>
<li>$P(B|A)/P(B)$: 调整因子，使得预估概率更接近真实概率；似然函数</li>
</ul>

<p><code>$$
后验概率 = 先验概率 \times 调整因子
$$</code></p>

<p><strong>我们先预估一个&rdquo;先验概率&rdquo;，然后加入实验结果，看这个实验到底是增强还是削弱了&rdquo;先验概率&rdquo;，由此得到更接近事实的&rdquo;后验概率&rdquo;。</strong></p>

<h3 id="常见概率分布">常见概率分布</h3>

<ul>
<li>0-1分布/两点分布/伯努利分布(离散)</li>
</ul>

<p>分布律：</p>

<table>
<thead>
<tr>
<th>X</th>
<th>1</th>
<th>0</th>
</tr>
</thead>

<tbody>
<tr>
<td>p</td>
<td>p</td>
<td>1-p</td>
</tr>
</tbody>
</table>

<p>则期望、方差分别为:
<code>$$
E(X) = 1*p + 0*q = p \\\\\\
D(X) = E(X^2) - [E(X)]^2 = pq
$$</code></p>

<ul>
<li>二项分布</li>
</ul>

<p>设随机变量X服从参数为$n, p$的二项分布。</p>

<p>设$X_i$为第$i$次试验中时间A发生的次数，$i = 1,2,&hellip;, n$,则
<code>$$
X = \sum_1^nX_i
$$</code>
显然，$x_i$相互独立均服从参数为$p$的0-1分布</p>

<p><code>$$
E(X) = \sum_1^nE(X_i) = np \\\\\\
D(X) = \sum_1^nD(X_i) = np(1-p)
$$</code></p>

<ul>
<li>泊松分布</li>
</ul>

<p>设$X \sim \pi(\lambda)$，且分布律为:
<code>$$
P\{X=k\} = \frac{\lambda^k}{k!}e^{-\lambda}, k = 0,1,\ldots, \lambda \gt 0 \\\\\\
E(X) = \lambda  \\\\\\
D(X) = \lambda
$$</code>
其中，$\lambda$ 是单位时间内随机事件的平均发生率。</p>

<ul>
<li>均匀分布(连续的分布)</li>
</ul>

<p>设$X \sim U(a, b)$，其概率密度为：
<code>$$
f(x) =
\begin{cases}  
\frac{1}{b-a}, \qquad a \lt x \lt b\\\\\\
3n+1, \qquad otherwise
\end{cases}
$$</code>
则有
<code>$$
E(X) = \int_{-\infty}^{\infty}xf(x)dx=\int_{a}^b\frac{1}{b-a}xdx = \frac{1}{2}(a+b) \\\\\\
D(X) = E(X^2) - [E(X)]^2 = \int_{a}^bx^2\frac{1}{b-a}dx - [\frac{a+b}{2}]^2 = \frac{(b-a)^2}{12}
$$</code></p>

<ul>
<li>指数分布</li>
</ul>

<p>设随机变量X服从指数分布，其概率密度为：
<code>$$
f(x) =
\begin{cases}  
\lambda e^{-\lambda x} \quad x \gt 0\\\\\\
0, \qquad  x \le 0
\end{cases}
\lambda \gt 0
$$</code>
则有
<code>$$
E(X) = \theta \\\\\\
D(X) = \theta^2
$$</code>
<strong>指数分布的无记忆性</strong>, 如果一个随机变量呈指数分布, 当$s, t \ge 0$，则有:
<code>$$
P(x \gt s+t | x \gt s) = P(x \gt t)
$$</code></p>

<ul>
<li>正态分布</li>
</ul>

<p>设 $X \sim N(\mu, \theta^2)$, 其概率密度为:
<code>$$
f(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-u)^2}{2\sigma^2}}, \sigma \gt 0, -\infty \lt x \lt +\infty
$$</code>
则有:
<code>$$
E(X) = \mu \\\\\\\
D(X) = \sigma^2
$$</code></p>

<h3 id="sigmoid-logistic函数的引入">Sigmoid/Logistic函数的引入</h3>

<p>伯努利分布也属于指数族。
<code>$$
p(y;\phi) = \phi^y(1-\phi)^{1-y} \\\\\\
=exp(ylog\phi + (1-y)log(1-\phi)) \\\\\\
= exp((log(\frac{\phi}{1-\phi}))y+log(1-\phi))
$$</code>
The natural parameter is given by $\eta = log(\phi/(1-\phi))$, we obtain $\phi = 1/(1+e^{-\eta})$.</p>

<p>Sigmoid 函数$f(x) = \frac{1}{1+e^{-x}}$导数:
<code>$$
f'(x) = (\frac{1}{1+e^{-x}})'\\\\\\
=\frac{e^{-x}}{(1+e^{-x})^2} \\\\\\
=\frac{1}{1+e^{-x}}\frac{e^{-x}}{1+e^{-x}}\\\\\\
=\frac{1}{1+e^{-x}}[1 - \frac{1}{1+e^{-x}}]\\\\\\
=f(x) \times (1-f(x))
$$</code></p>

<h3 id="期望-方差-协方差-相关系数">期望/方差/协方差/相关系数</h3>

<ul>
<li>事件的独立性</li>
</ul>

<p>给定A和B两个时间，若有$P(AB) = P(A)P(B)$，则称事件A和B相互独立。</p>

<p>思考: 试给出A,B相互包含的信息量的定义$I(AB)$，要求:如果A,B独立，则$I(AB)=0$</p>

<ul>
<li>期望</li>
</ul>

<p><code>$$
离散 \qquad E(X) = \sum_ix_ip_i \\\\\\
连续 \qquad E(X) = \int_{-\infty}^{\infty}xf(x)dx
$$</code></p>

<p>无条件成立:
<code>$$
E(kX) = kE(X)\\\\\\
E(X+Y) = E(X) + E(Y)
$$</code>
若X,Y相互独立:
<code>$$
E(XY) = E(X)E(Y)
$$</code>
反之不一定成立。事实上，上式只能说明XY不相关。</p>

<ul>
<li>方差</li>
</ul>

<p><code>$$
Var(X) = E{[X-E(X)] ^2} = E(X^2) - E^2(X)
$$</code></p>

<p>无条件成立:
<code>$$
Var(c) = 0\\\\\\
Var(X+c) = Var(X)\\\\\\
Var(kX)=k^2Var(X)
$$</code>
若X,Y相互独立:
<code>$$
Var(X+Y) = Var(X) + Var(Y)
$$</code>
反之不一定成立。另外， 方差的平方根为标准差。</p>

<ul>
<li>协方差</li>
</ul>

<p><code>$$
Cov(X, Y) = E\{[X-E(X)][Y-E(Y)]\}
$$</code></p>

<p>性质:
<code>$$
Cov(X,  Y) = Cov(Y, X)\\\\\\
Cov(aX+b, cY+d) = acCov(X, Y)\\\\\\
Cov(X_1+X_2, Y) = Cov(X_1, Y)+Cov(X_2, Y)\\\\\\
Cov(X, Y) = E(XY) - E(X)E(Y)
$$</code>
如果X和Y独立时，$Cov(X, Y) = 0$; 但是如果$Cov(X, Y) = 0$, 我们称X和Y不相关。</p>

<p>意义: 协方差是两个随机变量具有相同方向变化趋势的变量的度量;</p>

<p>若$Cov(X, Y) \gt 0$, 它们的变化趋势相同;</p>

<p>若$Cov(X, Y) \lt 0$, 它们的变化趋势相反;</p>

<p>若$Cov(X, Y) = 0$, 它们不相关。</p>

<p>若X与Y不相关，说明X和Y之间没有线性关系(但是不能存在其他函数关系)，不能保证X和Y相互独立。</p>

<p>但是对于二位正太随机变量，X和Y不相关等价于X和Y相互独立。</p>

<ul>
<li>Pearson 相关系数</li>
</ul>

<p><code>$$
\rho_{xy} = \frac{Cov(X, Y)}{\sqrt{Var(X)Var(Y)}} \qquad |\rho| \le 1
$$</code></p>

<p>当且仅当X与Y有线性关系时，等号成立。</p>

<ul>
<li>协方差矩阵</li>
</ul>

<p>对于n个随机向量$(X_1, X_2, \ldots, X_n)$, 任意两个元素$X_i,X_j$都可以得到一个协方差，从而形成$n\times n$的矩阵，协方差矩阵是对称阵。
<code>$$
Cov(X_i, X_j) =
\begin{pmatrix}
c_{11} &amp; c_{12} &amp; \cdots &amp; c_{1n} \\\\\\
 c_{21} &amp; c_{22} &amp; \cdots &amp; c_{2n} \\\\\\
\vdots &amp; \vdots&amp; \vdots &amp; \ddots \\\\\\
 c_{n1} &amp; c_{n2} &amp; \cdots &amp; c_{nn}
\end{pmatrix}
$$</code></p>

<h3 id="大数定律">大数定律</h3>

<ul>
<li>切比雪夫不等式</li>
</ul>

<p>设随机变量X的期望为$\mu$, 方差为$\sigma^2$，对于任意正数$\epsilon$，有:
<code>$$
P\{|X-\mu|\ge \epsilon\} \le \frac{\sigma^2}{\epsilon^2}
$$</code></p>

<p>切比雪夫不等式说明，X的方差越小，事件${|X-\mu|\ge \epsilon}$发生的概率就越大。即X取的值基本集中在期望附近。</p>

<ul>
<li>大数定律</li>
</ul>

<p>设随机变量$X_1, X_2,\ldots, X_n,\ldots$相互独立，并且具有相同的期望$\mu$和方差$\sigma^2$。取前n个随机变量的平均<code>$Y_n=\frac{1}{n}\sum_{i=1}^nX_i$</code>，则对于任意正数$\epsilon$,有:
<code>$$
lim_{n\to\infty}P\{|Y_n-u| \lt \epsilon\} = 1
$$</code>
当n很大时，随机变量$X_1, X_2,\ldots, X_n$的平均值$Y_n$在概率原因下无线接近期望$\mu$. 当n无限大时，出现偏离的可能性为0。</p>

<h3 id="中心极限定理">中心极限定理</h3>

<p>设随机变量$X_1, X_2,\ldots, X_n,\ldots$互相独立，服从同一分布，并且具有相同的期望$\mu$和方差$\sigma^2$，则随机变量<code>$Y_n=\frac{1}{n}\sum_{i=1}^nX_i$</code>:
<code>$$
Y_n = \frac{\sum_{i=1}^nX_i-n\mu}{\sqrt{n}\sigma}
$$</code>
的分布收敛到<strong>标准正态分布</strong>。</p>

<p>且$\sum_{i=1}^nX_i$收敛到正态分布$N(n\mu, n\sigma^2)$。</p>

<h3 id="最大似然估计">最大似然估计</h3>

<p>就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值！</p>

<p><strong>换句话说，极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。</strong></p>

<p>设总体分布为$f(x,θ)$，且$X_1, X_2, \ldots, X_n$为该总体采样得到的样本。因为$X_1,X_2, \ldots, X_n$独立同分布，于是，它们的联合密度函数为:
<code>$$
L(x_1, x_2, \ldots, x_n; \theta_1, \theta_2, \ldots, \theta_k) =\prod_{i=1}^nf(x_i;  \theta_1, \theta_2, \ldots, \theta_k)
$$</code>
这里的$\theta$被看作模型固定但未知的参数。求参数$\theta$的值，使得似然函数取最大值，这种方法就只最大似然估计。</p>

<p>正态分布的最大似然估计：</p>

<p>过给定一组样本$X_1, X_2, \ldots, X_n$，已知他们来自于高斯分布$N(\mu, \sigma^2)$, 试估计参数$\mu, \sigma$.
<code>$$
\mu=\frac{1}{n}\sum_{i}x_i\\\\\\
\sigma^2 = \frac{1}{n}\sum_{i}(x_i-\mu)^2           
$$</code></p>

<h3 id="参考阅读">参考阅读</h3>

<p><a href="http://www.ruanyifeng.com/blog/2011/08/bayesian_inference_part_one.html">贝叶斯推断及其互联网应用（一）：定理简介</a></p>

<p><a href="https://zhuanlan.zhihu.com/p/26614750">一文搞懂极大似然估计</a></p>

    
    

    <h4>See also</h4>
    <ul>
        
            <li><a href="/2017/04/03/math-analysis/">机器学习之数学分析</a></li>
        
    </ul>


</article>



        </div>

        <aside class="col-12 col-lg-3 ml-auto blog-sidebar">
    
        


<section>
    <h4>Recent Posts</h4>
    <ol class="list-unstyled">
        
        <li>
            <a href="/2017/04/10/probability/">机器学习之概率论</a>
        </li>
        
        <li>
            <a href="/2017/04/03/math-analysis/">机器学习之数学分析</a>
        </li>
        
        <li>
            <a href="/2016/09/16/redis-lock/">基于redis的分布式锁的实现方案</a>
        </li>
        
        <li>
            <a href="/2016/09/11/golang-https-proxy/">创建基于proxy的HTTP(s)连接</a>
        </li>
        
        <li>
            <a href="/2016/09/04/go/">golang中context包</a>
        </li>
        
    </ol>
</section>

    
    
        <section>
    
        
    
        
        <h4>Categories</h4>
        <p>
            
            <a class="badge badge-primary" href="/categories/%E5%B7%A5%E5%85%B7%E7%AE%B1">工具箱</a>
            
            <a class="badge badge-primary" href="/categories/%E6%8A%80%E6%9C%AF%E5%BF%97">技术志</a>
            
            <a class="badge badge-primary" href="/categories/%E6%9D%82%E8%B0%88%E9%9B%86">杂谈集</a>
            
        </p>
        
    
        
    
        
        <h4>Tags</h4>
        <p>
            
            <a class="badge badge-primary" href="/tags/apache">apache</a>
            
            <a class="badge badge-primary" href="/tags/golang">golang</a>
            
            <a class="badge badge-primary" href="/tags/iptables">iptables</a>
            
            <a class="badge badge-primary" href="/tags/linux">linux</a>
            
            <a class="badge badge-primary" href="/tags/machine-learning">machine-learning</a>
            
            <a class="badge badge-primary" href="/tags/network">network</a>
            
            <a class="badge badge-primary" href="/tags/php">php</a>
            
            <a class="badge badge-primary" href="/tags/redis">redis</a>
            
            <a class="badge badge-primary" href="/tags/%E4%BB%A3%E7%90%86">代理</a>
            
            <a class="badge badge-primary" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8">分布式存储</a>
            
            <a class="badge badge-primary" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81">分布式锁</a>
            
            <a class="badge badge-primary" href="/tags/%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95">压力测试</a>
            
            <a class="badge badge-primary" href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%A7%E8%83%BD">服务器性能</a>
            
            <a class="badge badge-primary" href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%A8%A1%E5%9E%8B">服务器模型</a>
            
        </p>
        
    
</section>
    
</aside>


      </div>
    </div>
    

    
      <footer class="blog-footer w-100">
    <nav class="navbar navbar-light bg-light">
        <p class="w-100 text-center">Hugo template made with ❤ by <a href="https://github.com/Xzya">Xzya</a>, inspired by <a href="https://github.com/alanorth/hugo-theme-bootstrap4-blog">hugo-theme-bootstrap4-blog</a></p>
        <p class="w-100 text-center"><a href="#">Back to top</a></p>
    </nav>
</footer>
    

    
    
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
  </body>
</html>