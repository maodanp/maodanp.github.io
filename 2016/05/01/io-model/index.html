<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="服务器的I/O模型" />
<meta property="og:description" content="I/O模型的设计是后台服务能否支持高并发的至关因素。好的服务器性能必然需要良好的IO模型作为支撑。本篇重新复习下服务器常用的IO模型。

" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://maodanp.github.io/2016/05/01/io-model/" />



<meta property="article:published_time" content="2016-05-01T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2016-05-01T00:00:00&#43;00:00"/>











<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="服务器的I/O模型"/>
<meta name="twitter:description" content="I/O模型的设计是后台服务能否支持高并发的至关因素。好的服务器性能必然需要良好的IO模型作为支撑。本篇重新复习下服务器常用的IO模型。

"/>


    <link rel="canonical" href="http://maodanp.github.io/2016/05/01/io-model/">

    <title>
      
        服务器的I/O模型 | Danping&#39;s Blog
      
    </title>

    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <link href="http://maodanp.github.io/css/style.css" rel="stylesheet">

    

    

    
  </head>
  <body>
    
      <header class="blog-header">
    <nav class="navbar navbar-expand-md navbar-light bg-light">
        <a class="navbar-brand" href="/">
            Danping&#39;s Blog
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false"
            aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse justify-content-between" id="navbarNav">
            <ul class="navbar-nav">
                
                
                <li class="nav-item ">
                    <a class="nav-link" href="/">主页</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="/categories/%e6%8a%80%e6%9c%af%e5%bf%97/">技术志</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="/categories/%E5%B7%A5%E5%85%B7%E7%AE%B1/">工具箱</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="/categories/%e6%9d%82%e8%b0%88%e9%9b%86/">杂谈集</a>
                </li>
                
                <li class="nav-item ">
                    <a class="nav-link" href="/about/">关于</a>
                </li>
                
            </ul>
            
        </div>
	
    </nav>
</header>

    

    
    <div class="container">
      <div class="row">
        <div class="col-12 col-lg-8 blog-main">

          

<article class="blog-post">
    <header>
        <h2 class="blog-post-title">
            <a class="text-dark" href="/2016/05/01/io-model/">服务器的I/O模型</a>
        </h2>
        


<div class="blog-post-date text-secondary">
    
        May 1, 2016
    
    
        by Danping Mao
    
</div>
        
<div class="blog-post-tags text-secondary">
    <strong>Tags:</strong>
    
        <a class="badge badge-primary" href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%A7%E8%83%BD">服务器性能</a>
    
        <a class="badge badge-primary" href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%A8%A1%E5%9E%8B">服务器模型</a>
    
</div>

        
<div class="blog-post-categories text-secondary">
    <strong>Categories:</strong>
    
        <a class="badge badge-primary" href="/categories/%E6%8A%80%E6%9C%AF%E5%BF%97">技术志</a>
    
</div>

    </header>
    <hr>
    <p>I/O模型的设计是后台服务能否支持高并发的至关因素。好的服务器性能必然需要良好的IO模型作为支撑。本篇重新复习下服务器常用的IO模型。</p>

<p></p>

<p>I/O操作根据设备的不同分为很多种，如内存I/O、网络I/O、磁盘I/O等。相对于后两种I/O操作，内存I/O速度已经足够快了。尽管可以用多进程等方式来充分利用空闲的CPU资源，但CPU资源毕竟有限，而且在遇到高并发情况时，CPU调度、服务器资源数将成为很大的限制。</p>

<p>我们希望花让CPU花费足够少的时间在I/O的调度上，而是花在对I/O的操作处理上。如何让高速的CPU和慢速的I/O设备更好的协调工作，也是现代计算机处理高并发、高可用的一个持续的技术话题。</p>

<p>网络IO的本质是socket的流操作，当一个read操作发生时，实际需要经历两个阶段：
1. 等待数据就绪/准备（等待网络上的数据分组到达，然后被复制到内核的某个缓冲区）
2. 将数据从内核拷贝到用户进程空间（将数据从内核缓冲区复制到用户进程缓冲区）</p>

<p>由于网络I/O存在上述两个阶段的时间等待，所以网络I/O的延时将是影响服务器性能的主要瓶颈。好的I/O模型也是至关重要的。 网络I/O模型大致分为以下几种：
* 同步阻塞I/O
* 同步非阻塞IO/
* 多路复用I/O
* 信号驱动式I/O
* 异步I/O</p>

<h3 id="同步阻塞i-o">同步阻塞I/O</h3>

<p>同步阻塞I/O是指当进程调用某些涉及IO操作的系统调用或库函数时，进程暂停，等待IO操作完成再继续运行。在调用recv()/recvfrom()这个系统调用，发生在内核中等待数据和复制数据过程如下：
<img src="http://7xt5nc.com1.z0.glb.clouddn.com/pic/2016/2016-05-01-io-model-block.png" alt="" /></p>

<p>从上图看出，进程在I/O的两个阶段都被阻塞了。阻塞I/O在简单环境下较适用，如果没有其他事需要同时进行处理，阻塞I/O也不错。但是，如果存在多个连接的情况，则会引发问题。代码片段如下示例：</p>

<pre><code>char buf[1024];
int i, n;
while (i_still_want_to_read()) {
    for (i=0; i&lt;n_sockets; ++i) {
        n = recv(fd[i], buf, sizeof(buf), 0);
        if (n==0)
            handle_close(fd[i]);
        else if (n&lt;0)
            handle_error(fd[i], errno);
        else
            handle_input(fd[i], buf, n);
    }
}
</code></pre>

<p>即使fd[2]上最先有数据达到，对fd[0]和fd[1]的读取操作取得一些数据并且完成之前，程序不会试图从fd[2]进行读取。这就引起了累计的时延，影响整体的接收速度。</p>

<p>有时会用多进程或者多线程解决多个连接的问题。就是每个连接拥有独立的进程或者线程，这样一个连接上的I/O阻塞并不会影响其他任务连接的进程或线程。代码片段如下所示：</p>

<pre><code>void child(int fd)
{
    char outbuf[MAX_LINE+1];
    size_t outbuf_used = 0;
    ssize_t result;

    while (1) {
        result = recv(fd, outbuf,MAX_LINE, 0);
        if (result == 0) {
            break;
        } else if (result == -1) {
            perror(&quot;read&quot;);
            break;
        }
    }
    //use outbuf todo something
}

void run(void)
{
    //do something init socket
    while (1) {
        struct sockaddr_storage ss;
        socklen_t slen = sizeof(ss);
        int fd = accept(listener, (struct sockaddr*)&amp;ss, &amp;slen);
        if (fd &lt; 0) {
            perror(&quot;accept&quot;);
        } else {
            if (fork() == 0) {
                child(fd);
                exit(0);
            }
        }
    }
}
</code></pre>

<p>为每个连接创建一个进程或者线程是否可行呢？ 如果作为服务器，连接数达到成千上万个，如此多的进程或者线程并不是明智的选择。</p>

<h3 id="同步非阻塞i-o">同步非阻塞I/O</h3>

<p>同步非阻塞I/O的调用不会等待数据的就绪，如果数据不可读或可写，它会立即告诉进程。此时，read操作可能会返回一个错误代码，说明这个命令不能立即满足（EAGIN或EWOULDBLOCK）。流程如图所示：</p>

<p><img src="http://7xt5nc.com1.z0.glb.clouddn.com/pic/2016/2016-05-01-io-model-noblock.png" alt="" /></p>

<p>与阻塞I/O不一样，”非阻塞将大的整片时间的阻塞分成N多个小阻塞，所以进程不断地被CPU调度“，该模式会消耗CPU, 且需要对每个连接描述符fd进行内核调用，不论连接上是否有数据。由于该模式会消耗大量CPU，所以极少情况使用。代码片段如下所示：</p>

<pre><code>while (i_still_want_to_read()) {
    for (i=0; i &lt; n_sockets; ++i) {
        n = recv(fd[i], buf, sizeof(buf), 0);
        if (n == 0) {
            handle_close(fd[i]);
        } else if (n &lt; 0) {
            if (errno == EAGAIN)
                 ; /* The kernel didn't have any data for us to read. */
            else
                 handle_error(fd[i], errno);
         } else {
            handle_input(fd[i], buf, n);
         }
    }
}
</code></pre>

<h3 id="多路复用-i-o-multiplexing">多路复用(I/O multiplexing)</h3>

<p>多路复用I/O，就是我们常说的select/poll/epoll， 它提供了对大量文件描述法就绪检查的高性能方案，它允许进程通过一种方法来同时监视所有文件描述符，并可以快速获得所有就绪的文件描述符，然后只针对这些文件描述符进行访问。<strong>优势就是同时可以监听多个fd。</strong> 流程如图所示:</p>

<p><img src="http://7xt5nc.com1.z0.glb.clouddn.com/pic/2016/2016-05-01-io-model-io-multiplexing.png" alt="" /></p>

<p>当得知数据就绪后，就访问数据本身而言，仍然需要选择阻塞或非阻塞的访问方式（一般我们选择非阻塞方式，以防止任何意外的等待阻塞整个进程）。代码片段如下所示：</p>

<pre><code>while (i_still_want_to_read()) {
    int maxfd = -1;
    FD_ZERO(&amp;readset);
    for (i=0; i &lt; n_sockets; ++i) {
         if (fd[i]&gt;maxfd) maxfd = fd[i];
         FD_SET(fd[i], &amp;readset);
    }

    select(maxfd+1, &amp;readset, NULL, NULL, NULL);   //这里阻塞

    for (i=0; i &lt; n_sockets; ++i) {
        if (FD_ISSET(fd[i], &amp;readset)) {
            n = recv(fd[i], buf, sizeof(buf), 0);
            if (n == 0) {
                //对端关闭套接字
                handle_close(fd[i]);
            } else if (n &lt; 0) {
                //数据传输完，内核没数据了
                if (errno == EAGAIN)
                     ; /* The kernel didn't have any data for us to read. */
                else
                     handle_error(fd[i], errno);
             } else {
                handle_input(fd[i], buf, n);
             }
        }
    }
}
</code></pre>

<blockquote>
<p>在整个用户的进程中，进程是被select阻塞的，没有阻塞在真正的I/O系统调用（如recv/recvfrom）之上。从整个I/O执行过程来看，他们都是顺序执行的，因此可以归为同步模型（synchronous）,都是进程主动等待内核状态。</p>
</blockquote>

<h3 id="信号驱动式i-o">信号驱动式I/O</h3>

<p>我们也可以用信号，让内核在描述符就绪时发送SIGIO信号通知我们，该模型即为信号驱动式I/O。</p>

<p><img src="http://7xt5nc.com1.z0.glb.clouddn.com/pic/2016/2016-05-01-io-model-signal.png" alt="" /></p>

<p>这种模型的优势在于等待数据报到达期间进程不被阻塞。主循环可以继续执行。只要等待来自信号处理函数的通知。</p>

<h3 id="异步i-o">异步I/O</h3>

<p>异步I/O模型，该模型工作机制是：告知内核启动某个操作，并让在整个操作（包括将数据从内核复制到我们自己的缓冲区）完成后通知我们。I/O的两个阶段，进程都是非阻塞的。</p>

<p>Linux提供了AIO库函数实现异步，但基本都是用开源的异步IO库，如libevent、libv、libuv。</p>

<p>从内核的角度看，当它接收到一个异步read之后，首先它会立即，对用户进程不会造成阻塞。然后内核会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，内核会给用户进程发送一个signal或执行一个基于线程的回调函数来完成这次IO处理过程。</p>

<h3 id="五种i-o模型">五种I/O模型</h3>

<p>同步I/O做I/O操作时将进程阻塞。 之前的阻塞I/O、非阻塞I/O、I/O复用、信号驱动I/O 都属于同步I/O(这里定义的I/O操作就是例子中recvfrom这个系统调用)。异步I/O则不一样，进程发起I/O操作后，就直接返回，直到内核发送一个信号，告诉进程说I/O完成。下图给出各种I/O的比较：</p>

<p><img src="http://7xt5nc.com1.z0.glb.clouddn.com/pic/2016/2016-05-01-io-model-summarize.png" alt="" /></p>

<p>对于同步IO，都需要进程主动的调用 recvfrom来将数据拷贝到用户内存。而异步 I/O则完全不同。它就像是用户进程将整个IO操作交给了内核（kernel）完成，然后内核做完后发信号通知用户进程。</p>

<h3 id="参考阅读">参考阅读</h3>

<p><a href="http://www.cppblog.com/mysileng/archive/2013/02/04/197715.html">异步I/O简介</a></p>

<p>《 UNIX网络编程卷1 》：6.2节 I/O模型</p>

    
    

    <h4>See also</h4>
    <ul>
        
            <li><a href="/2016/04/25/apache-conf/">apache配置与性能</a></li>
        
            <li><a href="/2016/04/24/apache-bench/">ApacheBench(ab)压力测试</a></li>
        
    </ul>


</article>



        </div>

        <aside class="col-12 col-lg-3 ml-auto blog-sidebar">
    
        


<section>
    <h4>Recent Posts</h4>
    <ol class="list-unstyled">
        
        <li>
            <a href="/2017/05/20/linear-regression/">机器学习之线性回归</a>
        </li>
        
        <li>
            <a href="/2017/04/10/probability/">机器学习之概率论</a>
        </li>
        
        <li>
            <a href="/2017/04/03/math-analysis/">机器学习之数学分析</a>
        </li>
        
        <li>
            <a href="/2016/09/16/redis-lock/">基于redis的分布式锁的实现方案</a>
        </li>
        
        <li>
            <a href="/2016/09/11/golang-https-proxy/">创建基于proxy的HTTP(s)连接</a>
        </li>
        
    </ol>
</section>

    
    
        <section>
    
        
    
        
        <h4>Categories</h4>
        <p>
            
            <a class="badge badge-primary" href="/categories/%E5%B7%A5%E5%85%B7%E7%AE%B1">工具箱</a>
            
            <a class="badge badge-primary" href="/categories/%E6%8A%80%E6%9C%AF%E5%BF%97">技术志</a>
            
            <a class="badge badge-primary" href="/categories/%E6%9D%82%E8%B0%88%E9%9B%86">杂谈集</a>
            
        </p>
        
    
        
    
        
        <h4>Tags</h4>
        <p>
            
            <a class="badge badge-primary" href="/tags/apache">apache</a>
            
            <a class="badge badge-primary" href="/tags/golang">golang</a>
            
            <a class="badge badge-primary" href="/tags/iptables">iptables</a>
            
            <a class="badge badge-primary" href="/tags/linux">linux</a>
            
            <a class="badge badge-primary" href="/tags/machine-learning">machine-learning</a>
            
            <a class="badge badge-primary" href="/tags/network">network</a>
            
            <a class="badge badge-primary" href="/tags/php">php</a>
            
            <a class="badge badge-primary" href="/tags/redis">redis</a>
            
            <a class="badge badge-primary" href="/tags/%E4%BB%A3%E7%90%86">代理</a>
            
            <a class="badge badge-primary" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8">分布式存储</a>
            
            <a class="badge badge-primary" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81">分布式锁</a>
            
            <a class="badge badge-primary" href="/tags/%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95">压力测试</a>
            
            <a class="badge badge-primary" href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%A7%E8%83%BD">服务器性能</a>
            
            <a class="badge badge-primary" href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%A8%A1%E5%9E%8B">服务器模型</a>
            
            <a class="badge badge-primary" href="/tags/%E6%AD%A3%E5%88%99%E5%8C%96">正则化</a>
            
            <a class="badge badge-primary" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92">线性回归</a>
            
        </p>
        
    
</section>
    
</aside>


      </div>
    </div>
    

    
      <footer class="blog-footer w-100">
    <nav class="navbar navbar-light bg-light">
        <p class="w-100 text-center">Hugo template made with ❤ by <a href="https://github.com/Xzya">Xzya</a>, inspired by <a href="https://github.com/alanorth/hugo-theme-bootstrap4-blog">hugo-theme-bootstrap4-blog</a></p>
        <p class="w-100 text-center"><a href="#">Back to top</a></p>
    </nav>
</footer>
    

    
    
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
  </body>
</html>